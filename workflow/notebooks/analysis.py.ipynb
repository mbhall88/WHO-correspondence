{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77134748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict, Counter\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "from enum import Enum\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from math import sqrt\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "if \"snakemake\" in locals() or \"snakemake\" in globals():\n",
    "    plt.rcParams['figure.figsize'] = snakemake.params.figsize\n",
    "    plt.rcParams['figure.dpi'] = snakemake.params.dpi\n",
    "    csvs = snakemake.input.csvs\n",
    "    qc = pd.read_csv(snakemake.input.qc)\n",
    "    cov_threshold = snakemake.params.cov_threshold\n",
    "    phenotypes = pd.read_csv(snakemake.input.samplesheet, index_col=\"run\")\n",
    "    ignore_drugs = snakemake.params.ignore_drugs\n",
    "    CONF = snakemake.params.conf_interval\n",
    "    minor_is_susceptible = snakemake.params.minor_is_susceptible\n",
    "    panel_names = snakemake.params.panel_names\n",
    "    outpath = snakemake.output.table\n",
    "    plots = snakemake.output.plots\n",
    "    who_results = pd.read_csv(snakemake.input.who_results)\n",
    "else:\n",
    "    plt.rcParams['figure.figsize'] = (13, 8)\n",
    "    plt.rcParams['figure.dpi'] = 300\n",
    "    csvs = list(Path(\"../../results/amr_predictions/\").glob(\"*.csv\"))\n",
    "    qc = pd.read_csv(\"../../results/qc.csv\")\n",
    "    cov_threshold = 15\n",
    "    phenotypes = pd.read_csv(\"../../docs/samplesheet.csv\", index_col=\"run\")\n",
    "    ignore_drugs = {\"Ciprofloxacin\", \"Ofloxacin\"}\n",
    "    CONF = 0.95\n",
    "    minor_is_susceptible = False\n",
    "    panel_names = {\n",
    "        \"previous\": \"Walker et al.\",\n",
    "        \"who2021\": \"WHO only\",\n",
    "        \"hunt2019\": \"Mykrobe\",\n",
    "        \"hall2022\": \"Combined\"\n",
    "    }\n",
    "    outpath = \"table.csv\"\n",
    "    plots = [\"plot.png\"]\n",
    "    who_results = pd.read_csv(\"../../docs/who-results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd41ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(csvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c296504f",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "for p in csvs:\n",
    "    frames.append(pd.read_csv(p))\n",
    "\n",
    "df = pd.concat(frames).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69061ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "passed_qc = set(qc.query(\"coverage >= @cov_threshold\")[\"run\"])\n",
    "len(passed_qc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb848ce5",
   "metadata": {},
   "source": [
    "Remove DST results for any sample with Illumina coverage below the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f0fa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.query(\"run in @passed_qc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a57d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prediction(Enum):\n",
    "    Resistant = \"R\"\n",
    "    Susceptible = \"S\"\n",
    "    MinorResistance = \"r\"\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return self.value\n",
    "    \n",
    "class Classification(Enum):\n",
    "    TruePositive = \"TP\"\n",
    "    FalsePositive = \"FP\"\n",
    "    TrueNegative = \"TN\"\n",
    "    FalseNegative = \"FN\"\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return self.value\n",
    "    \n",
    "class Classification(Enum):\n",
    "    TruePositive = \"TP\"\n",
    "    FalsePositive = \"FP\"\n",
    "    TrueNegative = \"TN\"\n",
    "    FalseNegative = \"FN\"\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return self.value\n",
    "\n",
    "\n",
    "class Classifier:\n",
    "    def __init__(\n",
    "        self,\n",
    "        minor_is_susceptible: bool = False,\n",
    "    ):\n",
    "        self.minor_is_susceptible = minor_is_susceptible\n",
    "        self.susceptible = {Prediction.Susceptible}\n",
    "        self.resistant = {Prediction.Resistant}\n",
    "        if self.minor_is_susceptible:\n",
    "            self.susceptible.add(Prediction.MinorResistance)\n",
    "        else:\n",
    "            self.resistant.add(Prediction.MinorResistance)\n",
    "\n",
    "\n",
    "    def from_predictions(\n",
    "        self, y_true: Prediction, y_pred: Prediction\n",
    "    ) -> Classification:\n",
    "        if y_true in self.susceptible:\n",
    "            expected_susceptible = True\n",
    "        elif y_true in self.resistant:\n",
    "            expected_susceptible = False\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Don't know how to classify {y_true} calls yet\")\n",
    "\n",
    "        if y_pred in self.susceptible:\n",
    "            called_susceptible = True\n",
    "        elif y_pred in self.resistant:\n",
    "            called_susceptible = False\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Don't know how to classify {y_pred} calls yet\")\n",
    "\n",
    "        if expected_susceptible and called_susceptible:\n",
    "            return Classification.TrueNegative\n",
    "        elif expected_susceptible and not called_susceptible:\n",
    "            return Classification.FalsePositive\n",
    "        elif not expected_susceptible and not called_susceptible:\n",
    "            return Classification.TruePositive\n",
    "        else:\n",
    "            return Classification.FalseNegative\n",
    "\n",
    "@dataclass\n",
    "class ConfusionMatrix:\n",
    "    tp: int = 0\n",
    "    tn: int = 0\n",
    "    fp: int = 0\n",
    "    fn: int = 0\n",
    "\n",
    "    def ravel(self) -> Tuple[int, int, int, int]:\n",
    "        \"\"\"Return the matrix as a flattened tuple.\n",
    "        The order of return is TN, FP, FN, TP\n",
    "        \"\"\"\n",
    "        return self.tn, self.fp, self.fn, self.tp\n",
    "\n",
    "    def as_matrix(self) -> np.ndarray:\n",
    "        \"\"\"Returns a 2x2 matrix [[TN, FP], [FN, TP]]\"\"\"\n",
    "        return np.array([[self.tn, self.fp], [self.fn, self.tp]])\n",
    "\n",
    "    def num_positive(self) -> int:\n",
    "        \"\"\"Number of TPs and FNs - i.e. actual condition positive\"\"\"\n",
    "        return self.tp + self.fn\n",
    "\n",
    "    def num_negative(self) -> int:\n",
    "        \"\"\"Number of TNs and FPs - i.e. actual condition negative\"\"\"\n",
    "        return self.tn + self.fp\n",
    "\n",
    "    def ppv(self) -> Tuple[float, float, float]:\n",
    "        \"\"\"Also known as precision\"\"\"\n",
    "        try:\n",
    "            ppv = self.tp / (self.tp + self.fp)\n",
    "            lwr_bound, upr_bound = confidence_interval(n_s=self.tp, n_f=self.fp)\n",
    "            return ppv, lwr_bound, upr_bound\n",
    "        except ZeroDivisionError:\n",
    "            return [None, None, None]\n",
    "\n",
    "    def npv(self) -> Tuple[float, float, float]:\n",
    "        \"\"\"Negative predictive value\"\"\"\n",
    "        try:\n",
    "            npv = self.tn / (self.tn + self.fn)\n",
    "            lwr_bound, upr_bound = confidence_interval(n_s=self.tn, n_f=self.fn)\n",
    "            return npv, lwr_bound, upr_bound\n",
    "        except ZeroDivisionError:\n",
    "            return [None, None, None]\n",
    "\n",
    "    def sensitivity(self) -> Tuple[float, float, float]:\n",
    "        \"\"\"Also known as recall and true positive rate (TPR)\"\"\"\n",
    "        try:\n",
    "            sn =  self.tp / self.num_positive()\n",
    "            lwr_bound, upr_bound = confidence_interval(n_s=self.tp, n_f=self.fn)\n",
    "            return sn, lwr_bound, upr_bound\n",
    "        except ZeroDivisionError:\n",
    "            return None, None, None\n",
    "\n",
    "    def specificity(self) -> Tuple[float, float, float]:\n",
    "        \"\"\"Also known as selectivity and true negative rate (TNR)\"\"\"\n",
    "        try:\n",
    "            sp = self.tn / self.num_negative()\n",
    "            lwr_bound, upr_bound = confidence_interval(n_s=self.tn, n_f=self.fp)\n",
    "            return sp, lwr_bound, upr_bound\n",
    "        except ZeroDivisionError:\n",
    "            return None, None, None\n",
    "\n",
    "    def fnr(self) -> Tuple[float, float, float]:\n",
    "        \"\"\"False negative rate or VME (very major error rate)\"\"\"\n",
    "        try:\n",
    "            fnr = self.fn / self.num_positive()\n",
    "            lwr_bound, upr_bound = confidence_interval(n_s=self.fn, n_f=self.tp)\n",
    "            return fnr, lwr_bound, upr_bound\n",
    "        except ZeroDivisionError:\n",
    "            return [None, None, None]\n",
    "\n",
    "    def fpr(self) -> Tuple[float, float, float]:\n",
    "        \"\"\"False positive rate or ME (major error rate)\"\"\"\n",
    "        try:\n",
    "            fpr = self.fp / self.num_negative()\n",
    "            lwr_bound, upr_bound = confidence_interval(n_s=self.fp, n_f=self.tn)\n",
    "            return fpr, lwr_bound, upr_bound\n",
    "        except ZeroDivisionError:\n",
    "            return [None, None, None]\n",
    "\n",
    "    def f_score(self, beta: float = 1.0) -> float:\n",
    "        \"\"\"Harmonic mean of precision and recall.\n",
    "        When beta is set to 0, you get precision. When beta is set to 1, you get the\n",
    "        unweighted F-score which is the harmonic mean of precision and recall. Setting\n",
    "        beta to 2 weighs recall twice as much as precision. Setting beta to 0.5 weighs\n",
    "        precision twice as much as recall.\n",
    "        \"\"\"\n",
    "        ppv = self.precision()\n",
    "        tpr = self.recall()\n",
    "        if ppv is None or tpr is None:\n",
    "            return None\n",
    "        beta2 = beta ** 2\n",
    "\n",
    "        return ((beta2 + 1) * ppv * tpr) / ((beta2 * ppv) + tpr)\n",
    "\n",
    "    @staticmethod\n",
    "    def from_series(s: pd.Series) -> \"ConfusionMatrix\":\n",
    "        tp = s.get(\"TP\", 0)\n",
    "        fp = s.get(\"FP\", 0)\n",
    "        fn = s.get(\"FN\", 0)\n",
    "        tn = s.get(\"TN\", 0)\n",
    "        return ConfusionMatrix(tp=tp, fn=fn, fp=fp, tn=tn)\n",
    "\n",
    "\n",
    "def confidence_interval(n_s: int, n_f: int, conf: float = CONF) -> Tuple[float, float]:\n",
    "    \"\"\"Calculate the Wilson score interval.\n",
    "    Equation take from https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval#Wilson_score_interval\n",
    "    n_s: Number of successes or, in the case of confusion matrix statistics, the numerator\n",
    "    n_f: Number of failures or, in the case of confusion matrix statistics, the denominator minus the numerator\n",
    "    conf: the confidence level. i.e. 0.95 is 95% confidence\n",
    "    \"\"\"\n",
    "    n = n_f + n_s\n",
    "    z = stats.norm.ppf(1 - (1 - conf) / 2)  # two-sided\n",
    "    z2 = z ** 2\n",
    "    nz2 = n + z2\n",
    "    A = (n_s + (0.5 * z2)) / nz2\n",
    "    B = z / nz2\n",
    "    C = sqrt(((n_s * n_f) / n) + (z2 / 4))\n",
    "    CI = B * C\n",
    "    return A - CI, A + CI\n",
    "\n",
    "\n",
    "def round_up_to_base(x, base=10):\n",
    "    return int(x + (base - x) % base)\n",
    "\n",
    "\n",
    "def round_down_to_base(x, base=10):\n",
    "    return int(x - (x % base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8927c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.query(\"drug not in @ignore_drugs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6166c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Classifier(minor_is_susceptible=minor_is_susceptible)\n",
    "classifications = []\n",
    "for _, row in df.iterrows():\n",
    "    drug = row[\"drug\"].lower()\n",
    "    y_true = phenotypes.at[row[\"run\"], drug]\n",
    "    if pd.isna(y_true):\n",
    "        classifications.append(None)\n",
    "    else:\n",
    "        y_true = Prediction(y_true)\n",
    "        y_pred = Prediction(row[\"prediction\"])\n",
    "        clf = classifier.from_predictions(y_true, y_pred)\n",
    "        classifications.append(str(clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9507a43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"classification\"] = classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4219445",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2e3ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cms = defaultdict()\n",
    "DRUGS = set(df[\"drug\"])\n",
    "PANELS = set(df[\"panel\"])\n",
    "\n",
    "for drug, panel in product(DRUGS, PANELS):\n",
    "    s = df.query(\"drug == @drug and panel == @panel\").value_counts(\n",
    "        subset=[\"classification\"]\n",
    "    )\n",
    "    cm = ConfusionMatrix.from_series(s)\n",
    "    cms[(drug, panel)] = cm\n",
    "    \n",
    "DRUGS = sorted(DRUGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108a904f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "for (drug, panel), cm in cms.items():\n",
    "    sn = cm.sensitivity()[0]\n",
    "    sp = cm.specificity()[0]\n",
    "    metrics.append((drug, panel, sn, sp))\n",
    "\n",
    "summary_cols = [\n",
    "    \"drug\",\n",
    "    \"panel\",\n",
    "    \"Sensitivity\",\n",
    "    \"Specificity\",\n",
    "]\n",
    "\n",
    "summary = pd.DataFrame(\n",
    "    metrics,\n",
    "    columns=summary_cols,\n",
    ").melt(id_vars=[\"drug\", \"panel\"], var_name=\"metric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f25af8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df.groupby([\"drug\", \"panel\", \"classification\"])[\"run\"].count()\n",
    "table = summary.set_index([\"drug\", \"panel\", \"metric\"])[\"value\"].unstack().reset_index()\n",
    "\n",
    "for clf in [\"TP\", \"FP\", \"FN\", \"TN\"]:\n",
    "    table[clf] = 0\n",
    "\n",
    "for i, row in table.iterrows():\n",
    "    ix = (row[\"drug\"], row[\"panel\"])\n",
    "    cm = cms[ix]\n",
    "    table.at[i, \"TP\"] = cm.tp\n",
    "    table.at[i, \"FP\"] = cm.fp\n",
    "    table.at[i, \"TN\"] = cm.tn\n",
    "    table.at[i, \"FN\"] = cm.fn\n",
    "    \n",
    "for k in [\"drug\", \"panel\"]:\n",
    "    table[k] = table[k].str.capitalize()\n",
    "\n",
    "table.fillna(\"-\", inplace=True)\n",
    "summary_cols = [\"drug\", \"panel\", \"Sensitivity\", \"Specificity\", \"TP\", \"TN\", \"FN\", \"FP\"]\n",
    "table = table[summary_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cc76bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "ci_str = (\n",
    "    lambda tup: f\"{tup[0]:.1%} ({tup[1]*100:.1f}-{tup[2]:.1%})\"\n",
    "    if tup[0] is not None\n",
    "    else \"-\"\n",
    ")\n",
    "for i, row in table.iterrows():\n",
    "    cm = ConfusionMatrix(tp=row[\"TP\"], fp=row[\"FP\"], tn=row[\"TN\"], fn=row[\"FN\"])\n",
    "    sn = cm.sensitivity()\n",
    "    sp = cm.specificity()\n",
    "    fn_str = f\"{cm.fn}({cm.num_positive()})\"\n",
    "    fp_str = f\"{cm.fp}({cm.num_negative()})\"\n",
    "    rows.append(\n",
    "        (\n",
    "            row[\"drug\"].capitalize(),\n",
    "            panel_names[row[\"panel\"].lower()],\n",
    "            fn_str,\n",
    "            fp_str,\n",
    "            ci_str(sn),\n",
    "            ci_str(sp),\n",
    "        )\n",
    "    )\n",
    "pretty_cols = [\n",
    "    \"Drug\",\n",
    "    \"Catalogue\",\n",
    "    \"FN(R)\",\n",
    "    \"FP(S)\",\n",
    "    \"Sensitivity (95% CI)\",\n",
    "    \"Specificity (95% CI)\",\n",
    "]\n",
    "table = pd.DataFrame(rows, columns=pretty_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06ab56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_data = []\n",
    "for _, row in who_results.iterrows():\n",
    "    panel = panel_names[\"previous\"]\n",
    "    sn = f\"{row['sensitivity']}% ({row['sensitivity_lower_bound']}%-{row['sensitivity_upper_bound']}%)\"\n",
    "    sp = f\"{row['specificity']}% ({row['specificity_lower_bound']}%-{row['specificity_upper_bound']}%)\"\n",
    "    paper_data.append((row[\"drug\"].capitalize(), panel, \"-\", \"-\", sn, sp))\n",
    "paper_tbl = pd.DataFrame(paper_data, columns=table.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c12253",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.concat([paper_tbl, table]).reset_index(drop=True).sort_values([\"Drug\", \"Catalogue\"], ascending=[True, False]).reset_index(drop=True)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04652ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_data = []\n",
    "sp_data = []\n",
    "for drug, panel in product(DRUGS, PANELS):\n",
    "    s = df.query(\"drug == @drug and panel == @panel\").value_counts(\n",
    "        subset=[\"classification\"]\n",
    "    )\n",
    "    cm = ConfusionMatrix.from_series(s)\n",
    "    sn = cm.sensitivity()\n",
    "    sp = cm.specificity()\n",
    "    sn_data.append((drug, panel, *sn))\n",
    "    sp_data.append((drug, panel, *sp))\n",
    "    \n",
    "sn_df = pd.DataFrame(sn_data, columns=[\"drug\", \"panel\", \"value\", \"lower\", \"upper\"])\n",
    "sp_df = pd.DataFrame(sp_data, columns=[\"drug\", \"panel\", \"value\", \"lower\", \"upper\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0196e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "DRUGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fadf147",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivities = []\n",
    "for d in DRUGS:\n",
    "    sensitivities.append(np.mean(sn_df.query(\"drug==@d\")[\"value\"]))\n",
    "sensitivities = np.array(sensitivities)\n",
    "drugix = np.array(list(reversed(np.argsort(sensitivities))))\n",
    "ordered_drugs = np.array(DRUGS)[drugix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f53048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_drugs(a):\n",
    "    xs = [d.lower() for d in ordered_drugs.tolist()]\n",
    "    out = []\n",
    "    c = Counter()\n",
    "    for x in a:\n",
    "        i = xs.index(x.lower())\n",
    "        d = xs[i]\n",
    "        c[d] += 1\n",
    "        out.append((i, c[d]))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac21f248",
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_df = sn_df.sort_values(by=\"drug\", key=sort_drugs).reset_index(drop=True)\n",
    "sp_df = sp_df.sort_values(by=\"drug\", key=sort_drugs).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09365852",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"\"\"AMK amikacin\n",
    "BDQ bedaquiline\n",
    "CAP capreomycin\n",
    "CFZ clofazimine\n",
    "CFX ciprofloxacin\n",
    "DLM delamanid\n",
    "EMB ethambutol\n",
    "ETO ethionamide\n",
    "FQ fluoroquinolone\n",
    "INH isoniazid\n",
    "KAN kanamycin\n",
    "LFX levofloxacin\n",
    "LZD linezolid\n",
    "MFX moxifloxacin\n",
    "OFX ofloxacin\n",
    "PTO prothionamide\n",
    "PZA pyrazinamide\n",
    "RIF rifampicin\n",
    "STM streptomycin\"\"\"\n",
    "abbrev = dict()\n",
    "for line in s.splitlines():\n",
    "    ab, d = line.split()\n",
    "    abbrev[d.capitalize()] = ab\n",
    "abbrev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3bffb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axR = plt.subplots()\n",
    "axS = axR.twiny()\n",
    "ggplot_cm = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "red = ggplot_cm[0]\n",
    "blue = ggplot_cm[1]\n",
    "purple = ggplot_cm[2]\n",
    "black = ggplot_cm[3]\n",
    "yellow = ggplot_cm[4]\n",
    "green = ggplot_cm[5]\n",
    "edgecol = \"black\"\n",
    "cmap = [purple, black, yellow]\n",
    "# plot details\n",
    "bar_width = 0.2\n",
    "epsilon = 0.05\n",
    "line_width = 0.5\n",
    "fs = 12\n",
    "rotate = 0\n",
    "capsize = 2\n",
    "alpha = 1.0\n",
    "bar_alpha = 0.6\n",
    "hatch = \"\"\n",
    "\n",
    "all_positions = []\n",
    "i = -1\n",
    "for panel in panel_names:\n",
    "    if panel == \"previous\":\n",
    "        continue\n",
    "    i += 1\n",
    "    ix = (d, panel)\n",
    "    panel_sn_df = sn_df.query(\"panel==@panel\")\n",
    "    sn_ys = panel_sn_df[\"value\"] * 100\n",
    "    sn_lb = sn_ys - panel_sn_df[\"lower\"] * 100\n",
    "    sn_ub = panel_sn_df[\"upper\"] * 100 - sn_ys\n",
    "    \n",
    "    positions = [p + ((bar_width + epsilon) * i) for p in np.arange(len(sn_ys))]\n",
    "    if panel == \"who2021\":\n",
    "        who_positions = np.array(positions)\n",
    "        \n",
    "    all_positions.append(positions)\n",
    "    \n",
    "    colour = cmap[i]\n",
    "    label = panel_names[panel.lower()]\n",
    "\n",
    "    # resistance bar plots\n",
    "    sn_bar = axR.bar(\n",
    "        positions,\n",
    "        sn_ys,\n",
    "        bar_width,\n",
    "        yerr=[sn_lb, sn_ub],\n",
    "        color=colour,\n",
    "        edgecolor=edgecol,\n",
    "        linewidth=line_width,\n",
    "        capsize=capsize,\n",
    "        alpha=bar_alpha,\n",
    "        label=label,\n",
    "    )\n",
    "\n",
    "    panel_sp_df = sp_df.query(\"panel==@panel\")\n",
    "    sp_ys = panel_sp_df[\"value\"] * 100\n",
    "    sp_lb = sp_ys - panel_sp_df[\"lower\"] * 100\n",
    "    sp_ub = panel_sp_df[\"upper\"] * 100 - sp_ys\n",
    "    sp_ub = [min(100, x) for x in sp_ub]\n",
    "    \n",
    "    sp_bar = axS.bar(\n",
    "        positions,\n",
    "        height=-(100-sp_ys),\n",
    "        bottom=100,\n",
    "        width=bar_width*0.75,\n",
    "        yerr=[sp_lb, sp_ub],\n",
    "        alpha=bar_alpha,\n",
    "        color=colour,\n",
    "        edgecolor=edgecol,\n",
    "        linewidth=line_width,\n",
    "        capsize=capsize,\n",
    "        error_kw=dict(barsabove=True),\n",
    "        label=label,\n",
    "    )\n",
    "    \n",
    "\n",
    "\n",
    "# add errorbars for paper sensitivity\n",
    "paper_cat = panel_names[\"previous\"]\n",
    "paper_df = who_results.sort_values(by=\"drug\", key=sort_drugs).reset_index(drop=True)\n",
    "offset = 0.05\n",
    "xs = who_positions-offset#[np.mean(ps)-0.1 for ps in zip(*all_positions)]\n",
    "metric = \"sensitivity\"\n",
    "ys = np.array(paper_df[metric])\n",
    "yerr_l = ys - paper_df[f\"{metric}_lower_bound\"]\n",
    "yerr_u = paper_df[f\"{metric}_upper_bound\"] - ys\n",
    "yerr_u = [min(100, x) for x in yerr_u]\n",
    "axR.errorbar(\n",
    "    xs, \n",
    "    ys, \n",
    "    yerr=[yerr_l, yerr_u], \n",
    "    color=red, \n",
    "    capsize=capsize, \n",
    "    fmt=\".--\", \n",
    "    alpha=0.9, \n",
    "    linewidth=line_width,\n",
    "    label=metric.capitalize()\n",
    ")\n",
    "\n",
    "# add errorbars for paper specificity\n",
    "paper_cat = panel_names[\"previous\"]\n",
    "paper_df = who_results.sort_values(by=\"drug\", key=sort_drugs).reset_index(drop=True)\n",
    "metric = \"specificity\"\n",
    "ys = np.array(paper_df[metric])\n",
    "yerr_l = ys - paper_df[f\"{metric}_lower_bound\"]\n",
    "yerr_u = paper_df[f\"{metric}_upper_bound\"] - ys\n",
    "yerr_u = [min(100, x) for x in yerr_u]\n",
    "axR.errorbar(\n",
    "    xs, \n",
    "    ys, \n",
    "    yerr=[yerr_l, yerr_u], \n",
    "    color=blue, \n",
    "    capsize=capsize, \n",
    "    fmt=\".--\", \n",
    "    alpha=0.9, \n",
    "    linewidth=line_width,\n",
    "    label=metric.capitalize()\n",
    ")\n",
    "    \n",
    "labels = [abbrev[d] for d in ordered_drugs]\n",
    "label_pos = [np.mean(ps) for ps in zip(*all_positions)]\n",
    "plt.xticks(label_pos, labels, rotation=rotate, fontsize=fs)\n",
    "axR.set_ylabel(\"value (%)\")\n",
    "yticks = [30, 40, 50, 60, 70, 80, 85, 90, 95, 100]\n",
    "axR.set_yticks(yticks)\n",
    "axR.set_yticklabels(yticks)\n",
    "axR.set_xticks(label_pos)\n",
    "axR.set_xticklabels(axS.get_xticklabels(), rotation=rotate, fontsize=fs)\n",
    "axR.tick_params(\"both\", labelsize=fs)\n",
    "\n",
    "plt.text(-0.6, 2,\n",
    "    \"Sensitivity ➜\", \n",
    "    rotation=\"vertical\", \n",
    "    fontsize=fs,\n",
    ")\n",
    "plt.text(12.9, 82,\n",
    "    \"Specificity ➜\", \n",
    "    rotation=270, \n",
    "    fontsize=fs,\n",
    ")\n",
    "\n",
    "leghandles, leglabels = axR.get_legend_handles_labels()\n",
    "legend_props = dict(loc=\"upper right\", prop=dict(size=fs), frameon=False, title_fontproperties=dict(size=fs-1, weight=\"bold\"))\n",
    "axR.legend(leghandles[:-2], leglabels[:-2], title=\"Catalogue\", bbox_to_anchor=(1, 0.84), **legend_props)\n",
    "axS.legend(leghandles[-2:], leglabels[-2:], title=\"Walker et al.\", bbox_to_anchor=(1, 0.68), **legend_props)\n",
    "axS.grid(False)\n",
    "axR.grid(False, axis=\"x\",)\n",
    "_ = axR.set_xlabel(\"Drug\", fontsize=fs+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e51f85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig.savefig(\"../../docs/submission/figure1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9108ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for plot_path in plots:\n",
    "    fig.savefig(plot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b129c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(table.to_latex(index=False).replace(\".\", \"·\").replace(\"l·\", \"l.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dad0f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outpath, \"w\") as fp:\n",
    "    print(table.to_csv(index=False).replace(\".\", \"·\").replace(\"l·\", \"l.\"), file=fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7176014b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for drug in set(table[\"Drug\"]):\n",
    "    print(drug)\n",
    "    rows = table.query(\"Drug==@drug and Catalogue in ['Mykrobe', 'Combined']\").sort_values(\"Catalogue\", ascending=False)\n",
    "    sn1 = rows[\"Sensitivity (95% CI)\"].iloc[0].split()[0][:-1]\n",
    "    if not sn1:\n",
    "        continue\n",
    "    sn1 = float(sn1)\n",
    "    sn2 = float(rows[\"Sensitivity (95% CI)\"].iloc[1].split()[0][:-1])\n",
    "    sndiff = sn1-sn2\n",
    "    sp1 = float(rows[\"Specificity (95% CI)\"].iloc[0].split()[0][:-1])\n",
    "    sp2 = float(rows[\"Specificity (95% CI)\"].iloc[1].split()[0][:-1])\n",
    "    spdiff = sp1-sp2\n",
    "    print(f\"Sn diff. {sndiff:.1f}\\tSp diff. {spdiff:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9695862e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
